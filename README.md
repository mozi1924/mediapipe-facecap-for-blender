# Mozi's Facemocap for Blender

[中文文档](/README_ZH.md)

## Introduction
A MediaPipe-based facial capture program primarily designed for Blender, consisting of a companion Blender addon (referred to as the "receiver") and a transmitter.

It converts facial data into simple transformations (e.g., movement, scaling) for control bones in Blender. Compared to existing facial capture plugins, it is simpler, more intuitive, and offers better compatibility. Theoretically, it works with any facial rigging system that follows similar operational logic.

## Features
- OpenCL hardware acceleration support
- UDP-based network transmission
- Linux compatibility (developed primarily on this OS)
- CSV recording support in the transmitter
- Headless mode (runs without a GUI)

## Usage
Download the version appropriate for your operating system from the releases page

Then create the `_internal/mediapipe/modules` folder

Unzip modules.zip into it

tree
```
~/myapp/main/_internal/mediapipe/modules$ tree
.
├── face_detection
│   ├── face_detection_full_range_cpu.binarypb
│   ├── face_detection_full_range_sparse.tflite
│   ├── face_detection_pb2.py
│   ├── face_detection_short_range_cpu.binarypb
│   └── face_detection_short_range.tflite
├── face_geometry
│   ├── data
│   │   └── __init__.py
│   ├── effect_renderer_calculator_pb2.py
│   ├── env_generator_calculator_pb2.py
│   ├── geometry_pipeline_calculator_pb2.py
│   ├── __init__.py
│   ├── libs
│   │   └── __init__.py
│   └── protos
│       ├── environment_pb2.py
│       ├── face_geometry_pb2.py
│       ├── geometry_pipeline_metadata_pb2.py
│       ├── __init__.py
│       └── mesh_3d_pb2.py
└── face_landmark
    ├── face_landmark_front_cpu.binarypb
    ├── face_landmark.tflite
    ├── face_landmark_with_attention.tflite
    └── __init__.py
```

## Manual Installation
Python 3.12 is recommended.
```bash
git clone https://github.com/mozi1924/mediapipe-facecap-for-blender.git

python -m venv venv

pip install mediapipe numpy pyyaml
```

```bash
python main.py --preview --input 1
```
Modify arguments as needed.

## Shortcut key
Currently only one, press `C` to calibrate the face

## Parameters
```bash
[mozi@navi]~/mediapipe-realtime-face/app-next% python main.py --help             
usage: main.py [-h] [--input INPUT] [--udp_ip UDP_IP] [--udp_port UDP_PORT] [--preview] [--no_smooth] [--record]
               [--record_fps RECORD_FPS] [--record_output RECORD_OUTPUT]

Facial capture transmitter

options:
  -h, --help            Show this help message and exit
  --input INPUT         Video input source
  --udp_ip UDP_IP       UDP target IP
  --udp_port UDP_PORT   UDP port number
  --preview             Enable real-time preview
  --no_smooth           Disable smoothing
  --record              Enable CSV recording
  --record_fps RECORD_FPS
                        Recording FPS (overrides config file)
  --record_output RECORD_OUTPUT
                        CSV output path (auto-generated by default)
```

## Receiver
Please read [addons.md](/addons.md)

## Don't know how to use it?
Try my example rig [example](/example/)

You will quickly understand the principles and become familiar with

Have fun :)

## License
GPL-3.0

## Contact
Email: mozi1924@arasaka.ltd  
BiliBili: https://space.bilibili.com/434156493

## Thanks
Helped me solve the big problem of head rotation https://github.com/shenasa-ai/head-pose-estimation